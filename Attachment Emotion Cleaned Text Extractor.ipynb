{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "30d52e07-d8a8-4749-a20f-b5273197c886",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9f012df0-87e9-4f21-a678-de9e28e38283",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "from os import walk\n",
    "import io\n",
    "\n",
    "import time\n",
    "from timeit import default_timer as timer\n",
    "from datetime import datetime\n",
    "\n",
    "import string\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import math\n",
    "\n",
    "import random\n",
    "from random import seed, randint, shuffle\n",
    "\n",
    "import json\n",
    "\n",
    "from statistics import mean, mode, stdev, median\n",
    "\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "59b8873f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "from transformers import pipeline\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7e414a0-89f5-4adb-b860-bb8d1b695e36",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "668bec95",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('../../attachment speech/LSTM_FT/Data/attachment_transcribed_lr_v1.csv', header=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9b9de5c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Extract Hidden Layer Output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf8bf8ba-b65f-4bf0-8f81-0e88d4b0a487",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f20ad731",
   "metadata": {},
   "outputs": [],
   "source": [
    "# classifier = pipeline(\"text-classification\",\n",
    "#                       model='bhadresh-savani/bert-base-uncased-emotion', top_k=None) #return_all_scores=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "57b898bf-98e7-42a5-878a-2f68460f21af",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers.models.bert.modeling_bert import (\n",
    "    BertPreTrainedModel,\n",
    "    BertModel,\n",
    "    BaseModelOutputWithPoolingAndCrossAttentions\n",
    "    #SequenceClassifierOutput\n",
    ")\n",
    "\n",
    "from transformers.file_utils import ModelOutput\n",
    "from transformers import BertForSequenceClassification\n",
    "from dataclasses import dataclass\n",
    "from typing import Optional, Tuple, Union, List\n",
    "\n",
    "@dataclass\n",
    "class SequenceClassifierOutput(ModelOutput):\n",
    "    loss: Optional[torch.FloatTensor] = None\n",
    "    logits: torch.FloatTensor = None\n",
    "    hidden_states: Optional[Tuple[torch.FloatTensor]] = None\n",
    "    pooled_hidden_states: Optional[Tuple[torch.FloatTensor]] = None\n",
    "    attentions: Optional[Tuple[torch.FloatTensor]] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1e5fa44d-5a16-4d43-b6b2-f9a9620139d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomBertForSequenceClassification(BertForSequenceClassification):\n",
    "    def forward(\n",
    "        self,\n",
    "        input_ids: Optional[torch.Tensor] = None,\n",
    "        attention_mask: Optional[torch.Tensor] = None,\n",
    "        token_type_ids: Optional[torch.Tensor] = None,\n",
    "        position_ids: Optional[torch.Tensor] = None,\n",
    "        head_mask: Optional[torch.Tensor] = None,\n",
    "        inputs_embeds: Optional[torch.Tensor] = None,\n",
    "        labels: Optional[torch.Tensor] = None,\n",
    "        output_attentions: Optional[bool] = None,\n",
    "        output_hidden_states: Optional[bool] = None,\n",
    "        return_dict: Optional[bool] = None,\n",
    "    ) -> Union[Tuple[torch.Tensor], SequenceClassifierOutput]:\n",
    "        r\"\"\"\n",
    "        labels (`torch.LongTensor` of shape `(batch_size,)`, *optional*):\n",
    "            Labels for computing the sequence classification/regression loss. Indices should be in `[0, ...,\n",
    "            config.num_labels - 1]`. If `config.num_labels == 1` a regression loss is computed (Mean-Square loss), If\n",
    "            `config.num_labels > 1` a classification loss is computed (Cross-Entropy).\n",
    "        \"\"\"\n",
    "        return_dict = return_dict if return_dict is not None else self.config.use_return_dict\n",
    "\n",
    "        outputs = self.bert(\n",
    "            input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            token_type_ids=token_type_ids,\n",
    "            position_ids=position_ids,\n",
    "            head_mask=head_mask,\n",
    "            inputs_embeds=inputs_embeds,\n",
    "            output_attentions=output_attentions,\n",
    "            output_hidden_states=output_hidden_states,\n",
    "            return_dict=return_dict,\n",
    "        )\n",
    "\n",
    "        pooled_output = outputs[1]\n",
    "\n",
    "        pooled_output = self.dropout(pooled_output)\n",
    "        logits = self.classifier(pooled_output)\n",
    "\n",
    "        loss = None\n",
    "        if labels is not None:\n",
    "            if self.config.problem_type is None:\n",
    "                if self.num_labels == 1:\n",
    "                    self.config.problem_type = \"regression\"\n",
    "                elif self.num_labels > 1 and (labels.dtype == torch.long or labels.dtype == torch.int):\n",
    "                    self.config.problem_type = \"single_label_classification\"\n",
    "                else:\n",
    "                    self.config.problem_type = \"multi_label_classification\"\n",
    "\n",
    "            if self.config.problem_type == \"regression\":\n",
    "                loss_fct = MSELoss()\n",
    "                if self.num_labels == 1:\n",
    "                    loss = loss_fct(logits.squeeze(), labels.squeeze())\n",
    "                else:\n",
    "                    loss = loss_fct(logits, labels)\n",
    "            elif self.config.problem_type == \"single_label_classification\":\n",
    "                loss_fct = CrossEntropyLoss()\n",
    "                loss = loss_fct(logits.view(-1, self.num_labels), labels.view(-1))\n",
    "            elif self.config.problem_type == \"multi_label_classification\":\n",
    "                loss_fct = BCEWithLogitsLoss()\n",
    "                loss = loss_fct(logits, labels)\n",
    "        if not return_dict:\n",
    "            output = (logits,) + outputs[2:]\n",
    "            return ((loss,) + output) if loss is not None else output\n",
    "\n",
    "        return SequenceClassifierOutput(\n",
    "            loss=loss,\n",
    "            logits=logits,\n",
    "            hidden_states=outputs.hidden_states,\n",
    "            pooled_hidden_states=pooled_output,\n",
    "            attentions=outputs.attentions,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "63e47142-0729-46de-a435-54162958a3e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the tokenizer and BERT model for sequence classification\n",
    "# tokenizer = AutoTokenizer.from_pretrained('bhadresh-savani/bert-base-uncased-emotion')\n",
    "# model = AutoModelForSequenceClassification.from_pretrained('bhadresh-savani/bert-base-uncased-emotion', \n",
    "#                                                            output_hidden_states=True, output_attentions=True, return_dict=True)\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained('bhadresh-savani/bert-base-uncased-emotion')\n",
    "model = CustomBertForSequenceClassification.from_pretrained('bhadresh-savani/bert-base-uncased-emotion', output_hidden_states=True, return_dict=True)\n",
    "\n",
    "# Define a function to process the text and get the classes and the output of the last hidden layer\n",
    "def get_logits_and_last_hidden_layer(text):\n",
    "    # Tokenize the text\n",
    "    inputs = tokenizer(text, return_tensors='pt')\n",
    "    # Forward pass through the BERT model\n",
    "    outputs = model(**inputs)\n",
    "    # Get the logits from the output\n",
    "    logits = outputs.logits\n",
    "    \n",
    "    # Get the output of the last hidden layer\n",
    "    last_hidden_layer = outputs.hidden_states[-1]\n",
    "    pooled_hidden_layer = outputs.pooled_hidden_states\n",
    "    \n",
    "    return logits, last_hidden_layer, pooled_hidden_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3f669292-4478-45a2-b094-92d61ab68f5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def logits2LabelsDF(logits):\n",
    "    scores = F.softmax(logits, dim=1).detach().numpy()[0]\n",
    "    labels = [{'label': model.config.id2label[i], 'score': score} for i, score in enumerate(scores)]\n",
    "\n",
    "    labelsDF = pd.DataFrame()\n",
    "    for label in labels:\n",
    "        labelsDF[label['label']] = [label['score']]\n",
    "\n",
    "    return labelsDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "80229702-14b0-40d4-bb22-659ae1c9a1c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tensor2JSON(last_hidden_layer):\n",
    "    # Convert the PyTorch tensor to a NumPy array\n",
    "    last_hidden_layer_np = last_hidden_layer.detach().numpy()\n",
    "    \n",
    "    # Convert the NumPy array to a Python list\n",
    "    last_hidden_layer_list = last_hidden_layer_np.tolist()\n",
    "    \n",
    "    # Serialize the Python list to JSON\n",
    "    last_hidden_layer_json = json.dumps(last_hidden_layer_list)\n",
    "\n",
    "    return last_hidden_layer_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5b713118-29de-49bf-ab3f-bfa431c12c8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tensor2Numpy(last_hidden_layer):\n",
    "    # Convert the PyTorch tensor to a NumPy array\n",
    "    last_hidden_layer_np = last_hidden_layer.detach().numpy()\n",
    "\n",
    "    return last_hidden_layer_np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7082d18d-8c7e-4a97-8b0a-f91414643845",
   "metadata": {},
   "outputs": [],
   "source": [
    "def poolOutput(hiddenOutputs):\n",
    "    pooledOutput = torch.cat(hiddenOutputs, dim=1)\n",
    "\n",
    "    return pooledOutput"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f386f36-9be9-47af-a642-8f0b0a368d7a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Extraction Chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "659c7665-34a5-4b9e-a18b-30348b2ec292",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Text'] = data['Text'].fillna('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6af68422-c845-49df-9c1b-c8053ec48004",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "065f7b7009194c6e967a2c3e7050931f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2399 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "currID, currTask, segment = data.iloc[0].ID, data.iloc[0].Task, 0\n",
    "subStoryHiddenOutputs = []\n",
    "\n",
    "threshold = 0.1 # 1 ms\n",
    "\n",
    "for index, row in tqdm(data.iterrows(), total=data.shape[0]):\n",
    "    childDF = row.copy().to_frame().T.reset_index(drop=True)\n",
    "   \n",
    "    if (childDF.ID[0]==currID and childDF.Task[0]==currTask):\n",
    "        segment += 1 \n",
    "    else: \n",
    "        if len(subStoryHiddenOutputs) > 0:\n",
    "            pooled_h_output = poolOutput(subStoryHiddenOutputs)\n",
    "            # with open(folderAPath+'Data/Audio/Merged/{}/{}.json'.format(row.Task, row.ID), 'w') as outfile:\n",
    "            #     outfile.write(tensor2JSON(pooled_h_output))   \n",
    "            np.savez_compressed('Data_V2/TextChunks/Merged/{}/{}.npy'.format(currTask, currID), tensor2Numpy(pooled_h_output))\n",
    "        \n",
    "        segment = 1\n",
    "        subStoryHiddenOutputs = []\n",
    "        currID, currTask = childDF.ID[0], childDF.Task[0]\n",
    "\n",
    "    if (childDF.End[0] - childDF.Start[0]) < threshold:\n",
    "        skippedDF = childDF.copy()\n",
    "        skippedDF['skipped_duration'] = childDF.End[0] - childDF.Start[0]\n",
    "\n",
    "        with open('Data_V2/TextChunks/attachment_emotions_text_skipped_segments_v1.csv', 'a') as f:\n",
    "            skippedDF.to_csv(f, mode='a', index=False, header=f.tell()==0)\n",
    "\n",
    "    else:\n",
    "        \n",
    "        storyResults, h_output, pooled_output = get_logits_and_last_hidden_layer(childDF.Text[0])\n",
    "        storyResultsDF = logits2LabelsDF(storyResults)\n",
    "    \n",
    "        subStoryHiddenOutputs.append(h_output)\n",
    "        \n",
    "        segDF = pd.concat([childDF, storyResultsDF], axis=1)\n",
    "        segDF['time'] = childDF.Start[0]\n",
    "        segDF['segment'] = segment\n",
    "    \n",
    "        # with open(folderAPath+'Data/Text/Unmerged/{}_{}_{}.json'.format(row.ID, row.Task, segment), 'w') as outfile:\n",
    "        #     outfile.write(tensor2JSON(h_output))\n",
    "    \n",
    "        np.savez_compressed('Data_V2/TextChunks/Unmerged/{}/{}_{}.npy'.format(row.Task, row.ID, segment), tensor2Numpy(h_output))\n",
    "    \n",
    "        np.savez_compressed('Data_V2/TextChunks/Pooled/{}/{}_{}.npy'.format(row.Task, row.ID, segment), tensor2Numpy(pooled_output))\n",
    "    \n",
    "        with open('Data_V2/TextChunks/attachment_emotions_text_v1.csv', 'a') as f:\n",
    "            segDF.to_csv(f, mode='a', index=False, header=f.tell()==0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
